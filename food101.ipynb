{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import Food101\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from pathlib import Path\n",
    "from torch.optim import lr_scheduler\n",
    "from torchmetrics import Precision, Recall, F1Score, ConfusionMatrix\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data'  # Directory where the dataset will be stored\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),  # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),# Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "food101_train = Food101(root=root, split='train', transform=transform, download=True)\n",
    "food101_test = Food101(root=root, split='test', transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Food101_dataloaders(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    batch_size:int,\n",
    "    num_workers:int):\n",
    "\n",
    "  class_names = train_dataset.classes\n",
    "  class_to_idx=train_dataset.class_to_idx\n",
    "\n",
    "  # Turn images into data loaders\n",
    "  train_dataloader = DataLoader(\n",
    "      train_dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "\n",
    "  test_dataloader = DataLoader(\n",
    "      test_dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False, # don't need to shuffle test data\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  return train_dataloader, test_dataloader, class_names,class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EfficientNet_V2(num_classes:int,\n",
    "                    freeze_percentage:float=0.5,\n",
    "                    tr_learning=False\n",
    "                    ):\n",
    "  weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "  #transform=weights.transforms\n",
    "  EfficientNet_V2=models.efficientnet_v2_s(weights=weights)\n",
    "  if tr_learning:\n",
    "    for param in EfficientNet_V2.parameters():\n",
    "      param.requires_grad=False\n",
    "\n",
    "    EfficientNet_V2.classifier=nn.Sequential(\n",
    "    nn.Dropout(p=0.2,inplace=True),\n",
    "    nn.Linear(in_features=1280,out_features=num_classes,bias=True)\n",
    "  )\n",
    "  else:\n",
    "    params = list(EfficientNet_V2.parameters())\n",
    "\n",
    "    # Calculate the number of parameters to freeze\n",
    "    num_params_to_freeze = int(len(params) * freeze_percentage)\n",
    "\n",
    "    # Randomly select parameters to freeze\n",
    "    params_to_freeze = random.sample(params, num_params_to_freeze)\n",
    "\n",
    "    # Freeze selected parameters\n",
    "    for param in params_to_freeze:\n",
    "       param.requires_grad = False\n",
    "\n",
    "    EfficientNet_V2.classifier=nn.Sequential(\n",
    "       nn.Dropout(p=0.2,inplace=True),\n",
    "       nn.Linear(in_features=1280,out_features=num_classes,bias=True)\n",
    "  )\n",
    "  return EfficientNet_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Workers=os.cpu_count()\n",
    "\n",
    "Food101_train_dataloader,Food101_test_dataloader,class_names,class_to_idx=Food101_dataloaders(train_dataset=food101_train,\n",
    "                                                                              \n",
    "                                                                              test_dataset=food101_test,\n",
    "                                                                              batch_size=40,\n",
    "                                                                              num_workers=Num_Workers\n",
    "                                                                              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
